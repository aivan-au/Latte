{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# Embeddings Comparison\n",
    "\n",
    "This notebook compares the performance of different embedding methods (MiniLM, MPNet, OpenAI, Gemini) for clustering Stack Exchange data. We use Optuna for hyperparameter optimization and evaluate clustering quality using Adjusted Rand Index (ARI).\n",
    "\n",
    "**Note:** This notebook requires additional dependencies not included in the main requirements.txt:\n",
    "```bash\n",
    "pip install optuna optuna-dashboard\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Latte import Latte\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "import optuna\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=optuna.exceptions.ExperimentalWarning)\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "project_to_field = {'biology': 'Science','chemistry': 'Science','physics': 'Science','ell': 'Language','english': 'Language','linguistics': 'Language','computergraphics': 'Design','graphicdesign': 'Design','photo': 'Design','gamedev': 'Tech','softwareengineering': 'Tech'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Helper Functions\n",
    "\n",
    "Define functions for hyperparameter optimization and data preprocessing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(obj, N, mask):\n",
    "    def objective(trial):\n",
    "        # Define discrete parameter spaces\n",
    "        reduce_val = trial.suggest_categorical('reduce_val', range(2, 51))\n",
    "        min_cluster_size = trial.suggest_categorical('min_cluster_size', range(2, 10))\n",
    "        min_samples = trial.suggest_categorical('min_samples', range(1, 10))\n",
    "        cluster_level = trial.suggest_categorical('cluster_level', range(0, 10))\n",
    "        \n",
    "        # Run your pipeline\n",
    "        obj.reduce(reduce_val)\n",
    "        obj.cluster(min_cluster_size=min_cluster_size, min_samples=min_samples)\n",
    "        cluster_labels = obj.get_cluster_labels(cluster_level)\n",
    "        \n",
    "        result = adjusted_rand_score(mask, cluster_labels)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    study= optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=N)\n",
    "    return study.best_trial.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(df):\n",
    "    df['field'] = df['project'].map(project_to_field)\n",
    "\n",
    "    mask1 = np.array(df['field'] == 'Science') * 1\n",
    "    mask2 = np.array(df['field'] == 'Language') * 2\n",
    "    mask3 = np.array(df['field'] == 'Design') * 3\n",
    "    mask4 = np.array(df['field'] == 'Tech') * 4\n",
    "\n",
    "    df['project_tags'] = df['project'] + '_' + df['tags']\n",
    "    masks = {\n",
    "        'field': mask1 + mask2 + mask3 + mask4,\n",
    "        'tag': pd.factorize(df['project_tags'])[0] + 1,\n",
    "        'project': pd.factorize(df['project'])[0] + 1\n",
    "    }\n",
    "    return masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 3\n",
    "df = pd.read_csv(f'data/sample_{sample_size}.csv')\n",
    "masks = get_masks(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## Comparison Across Different Sample Sizes\n",
    "\n",
    "We'll compare embedding methods across different sample sizes to see how performance scales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sample Size: 3 documents per project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field\n",
      "minilm: 0.29958105138884333\n",
      "mpnet: 0.21993258127185308\n",
      "openai: 0.47318915177898285\n",
      "gemini: 0.6903843235861531\n",
      "tag\n",
      "minilm: 0.2614492753623188\n",
      "mpnet: 0.24209160762398962\n",
      "openai: 0.2620481927710843\n",
      "gemini: 0.311268620855358\n",
      "project\n",
      "minilm: 0.33350710900473934\n",
      "mpnet: 0.3794954918447979\n",
      "openai: 0.5260757913936689\n",
      "gemini: 0.7280052524770204\n"
     ]
    }
   ],
   "source": [
    "for mask in masks:\n",
    "    print(mask)\n",
    "    for embeddings in ['minilm', 'mpnet', 'openai', 'gemini']:\n",
    "        latte = Latte(df, mute = True)\n",
    "        latte.embed('file', embeddings_file=f'embeddings/sample_{sample_size}_{embeddings}.pkl')\n",
    "        score = get_score(latte, 50, masks[mask])\n",
    "        print(f'{embeddings}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sample Size: 5 documents per project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field\n",
      "minilm: 0.4024136619470495\n",
      "mpnet: 0.34188214937998657\n",
      "openai: 0.6044783922252733\n",
      "gemini: 0.6397180021937082\n",
      "tag\n",
      "minilm: 0.2460930215210175\n",
      "mpnet: 0.32268177981430124\n",
      "openai: 0.3714250217418313\n",
      "gemini: 0.38263509411050395\n",
      "project\n",
      "minilm: 0.39973845257920493\n",
      "mpnet: 0.44151490950811556\n",
      "openai: 0.6345054918614583\n",
      "gemini: 0.6104892777328705\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5\n",
    "df = pd.read_csv(f'data/sample_{sample_size}.csv')\n",
    "masks = get_masks(df)\n",
    "\n",
    "for mask in masks:\n",
    "    print(mask)\n",
    "    for embeddings in ['minilm', 'mpnet', 'openai', 'gemini']:\n",
    "        latte = Latte(df, mute = True)\n",
    "        latte.embed('file', embeddings_file=f'embeddings/sample_{sample_size}_{embeddings}.pkl')\n",
    "        score = get_score(latte, 50, masks[mask])\n",
    "        print(f'{embeddings}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sample Size: 10 documents per project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field\n",
      "minilm: 0.4914340800299857\n",
      "mpnet: 0.4633643979046883\n",
      "openai: 0.6066241848734035\n",
      "gemini: 0.6983557992368349\n",
      "tag\n",
      "minilm: 0.2975292183064978\n",
      "mpnet: 0.26095570778537663\n",
      "openai: 0.3540780749070084\n",
      "gemini: 0.3672245096341985\n",
      "project\n",
      "minilm: 0.45116893621902326\n",
      "mpnet: 0.4010987893924442\n",
      "openai: 0.6335473326176289\n",
      "gemini: 0.6187082485413894\n"
     ]
    }
   ],
   "source": [
    "sample_size = 10\n",
    "df = pd.read_csv(f'data/sample_{sample_size}.csv')\n",
    "masks = get_masks(df)\n",
    "\n",
    "for mask in masks:\n",
    "    print(mask)\n",
    "    for embeddings in ['minilm', 'mpnet', 'openai', 'gemini']:\n",
    "        latte = Latte(df, mute = True)\n",
    "        latte.embed('file', embeddings_file=f'embeddings/sample_{sample_size}_{embeddings}.pkl')\n",
    "        score = get_score(latte, 50, masks[mask])\n",
    "        print(f'{embeddings}: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### Sample Size: 20 documents per project\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "field\n",
      "minilm: 0.45917746030670925\n",
      "mpnet: 0.31942026577600713\n",
      "openai: 0.5437427916348974\n",
      "gemini: 0.43864853004956267\n",
      "tag\n",
      "minilm: 0.3125094033580749\n",
      "mpnet: 0.2655310331231111\n",
      "openai: 0.37495720110631847\n",
      "gemini: 0.4003139988803484\n",
      "project\n",
      "minilm: 0.39292344325157164\n",
      "mpnet: 0.44715785993947493\n",
      "openai: 0.6091664160495908\n",
      "gemini: 0.6043374601053005\n"
     ]
    }
   ],
   "source": [
    "sample_size = 20\n",
    "df = pd.read_csv(f'data/sample_{sample_size}.csv')\n",
    "masks = get_masks(df)\n",
    "\n",
    "for mask in masks:\n",
    "    print(mask)\n",
    "    for embeddings in ['minilm', 'mpnet', 'openai', 'gemini']:\n",
    "        latte = Latte(df, mute = True)\n",
    "        latte.embed('file', embeddings_file=f'embeddings/sample_{sample_size}_{embeddings}.pkl')\n",
    "        score = get_score(latte, 50, masks[mask])\n",
    "        print(f'{embeddings}: {score}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
